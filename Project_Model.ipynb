{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspark.sql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30426c51e95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named pyspark.sql"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Project_new').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "df = spark.read.csv('Final.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Schema of the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For low recommended 311 severity\n",
    "low_311 = df.filter(\"311_Severity_1 > (311_Severity_2 & 311_Severity_3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Medium recomended \n",
    "medium_311 = df.filter(\"311_Severity_2 > (311_Severity_3 & 311_Severity_1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Highly recommended\n",
    "high_311 = df.filter(\"311_Severity_3 > (311_Severity_2 & 311_Severity_3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For low crime\n",
    "low_crime = df.filter(\"Crime_Severity_1 > (Crime_Severity_2 & Crime_Severity_3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Medium crime condition\n",
    "medium_crime = df.filter(\"Crime_Severity_2 > (Crime_Severity_3 & Crime_Severity_1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#high crime condition\n",
    "high_crime = df.filter(\"Crime_Severity_3 > (Crime_Severity_2 & Crime_Severity_1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, coalesce, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#low is set as 1\n",
    "df_low_311 = low_311.withColumn(\"311_Status\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#medium is set as 2\n",
    "df_medium_311 = medium_311.withColumn(\"311_Status\", lit(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#high is set as 3\n",
    "df_high_311 = high_311.withColumn(\"311_Status\", lit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merged all the values to single column\n",
    "df_new = df_low_311.union(df_medium_311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_311 = df_new.union(df_high_311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#high crime is set as 1 which is low recommended\n",
    "df_low_crime = low_crime.withColumn(\"Crime_Status\", lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#medium crime is set as 2 which is medium recommended\n",
    "df_medium_crime = medium_crime.withColumn(\"Crime_Status\", lit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#low crime is set as 3 which is highly recommended\n",
    "df_high_crime = high_crime.withColumn(\"Crime_Status\", lit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merged data values in single column\n",
    "df_new_crime = df_low_crime.union(df_medium_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_crime = df_new_crime.union(df_high_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_311.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_crime.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Performed inner join on data\n",
    "final_df_1 = df_311.join(df_crime,df_311['311_Zip']== df_crime['311_Zip'], how = 'inner').alias(\"ZIPCODE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selected the columns that contained ZIPCODE,311_Status,Crime_Status,RES_RATING\n",
    "final_df = df_311.join(df_crime,df_311['311_Zip']== df_crime['Crime_Zip'], how = 'cross').select(df_311['311_Zip'].alias(\"ZIPCODE\"),df_311['311_Status'].alias(\"311_STATUS\"),df_crime['Crime_Status'].alias(\"COMPLAINT_STATUS\"),df_311['RATING'].alias(\"RES_RATING\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_zip = final_df.filter( (final_df['311_STATUS'] == 1) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] < 2.5) \n",
    "    |(final_df['311_STATUS'] == 1) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] < 2.5)\n",
    "    |(final_df['311_STATUS'] == 2) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] < 2.5)\n",
    "    |(final_df['311_STATUS'] == 2) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] < 2.5)\n",
    "    |(final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] < 2.5) \n",
    "    |(final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] < 2.5)\n",
    "    |(final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] >= 2.5) & (final_df['RES_RATING'] < 3.3)\n",
    "    |(final_df['311_STATUS'] == 2) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] >= 2.5) & (final_df['RES_RATING'] < 3.3)\n",
    "    |(final_df['311_STATUS'] == 1) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] >= 2.5) & (final_df['RES_RATING'] < 3.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medium_zip = final_df.filter( (final_df['311_STATUS'] == 2) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] >= 2.5) & (final_df['RES_RATING'] < 3.3)\n",
    "    |(final_df['311_STATUS'] == 1) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] > 3.3)\n",
    "    |(final_df['311_STATUS'] == 2) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] > 3.3)\n",
    "    |(final_df['311_STATUS'] == 1) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] >= 2.5) & (final_df['RES_RATING'] < 3.3)\n",
    "    |(final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] >= 2.5) & (final_df['RES_RATING'] < 3.3)\n",
    "    |(final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] > 3.3)                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_zip  = final_df.filter( (final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 3)  &  (final_df['RES_RATING'] >= 3.3) & (final_df['RES_RATING'] <= 5.0) \n",
    "                           |(final_df['311_STATUS'] == 3) & (final_df['COMPLAINT_STATUS'] == 1)  &  (final_df['RES_RATING'] >= 3.3) & (final_df['RES_RATING'] <= 5.0)\n",
    "                           |(final_df['311_STATUS'] == 2) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] >= 3.3) & (final_df['RES_RATING'] <= 5.0)\n",
    "                           |(final_df['311_STATUS'] == 1) & (final_df['COMPLAINT_STATUS'] == 2)  &  (final_df['RES_RATING'] >= 3.3) & (final_df['RES_RATING'] <= 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_zip = low_zip.withColumn(\"FINAL_STATUS\", lit(0))\n",
    "medium_zip = medium_zip.withColumn(\"FINAL_STATUS\", lit(1))\n",
    "high_zip = high_zip.withColumn(\"FINAL_STATUS\", lit(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = low_zip.union(medium_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final_output = output.union(high_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final_output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['ZIPCODE',\n",
    " '311_STATUS',\n",
    " 'COMPLAINT_STATUS',\n",
    " 'RES_RATING',\n",
    " ], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = assembler.transform(df_final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = output.select('features', 'FINAL_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applied logistic regression to train the model \n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status = LogisticRegression(labelCol='FINAL_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_model = status.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_and_labels = fitted_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#auc = model_eval.evaluate(pred_and_labels.predictions)\n",
    "model_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='FINAL_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc = model_eval.evaluate(pred_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applied decision trees to the model\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='FINAL_STATUS', outputCol='indexedLabel').fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresIndexer = VectorIndexer(inputCol = 'features', outputCol='indexedFeatures', maxCategories=4).fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = output.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[labelIndexer, featuresIndexer, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData.select('ZIPCODE').distinct().show(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData.filter(\"FINAL_STATUS == 2\" ).select(['ZIPCODE']).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels='Best','average','low'\n",
    "colors='red','green','blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "auc = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "treeModel = model.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sklearn.datasets as datasets\n",
    "#import pandas as pd\n",
    "#iris = datasets.load_iris()\n",
    "#df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "#y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#predictions = dt.DecisionTreeClassifier()\n",
    "#predictions.fit(trainingData,testData)\n",
    "#dtree = DecisionTreeClassifier()\n",
    "#dtree.fit(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.externals.six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dot_data = StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export_graphviz(dtree, out_file = dot_data,\n",
    " #              filled = True, rounded = True,\n",
    "  #             special_characters = True)\n",
    "#graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['ZIPCODE',\n",
    " '311_STATUS',\n",
    " 'COMPLAINT_STATUS',\n",
    " 'RES_RATING',\n",
    " ], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = assembler.transform(df_final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = output.select('features', 'FINAL_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol='FINAL_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = trained_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
